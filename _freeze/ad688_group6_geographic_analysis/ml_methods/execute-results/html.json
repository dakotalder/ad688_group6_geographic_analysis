{
  "hash": "285e822f783b4f5501e769d3cc73db29",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Machine Learning Methods\"\nsubtitle: \"Regression, Classification, Topic Insights\"\nauthor:\n  - Dakota Alder\n  - Julio Garcia\nformat: \n  html:\n    toc: true\n    number-sections: true\n    df-print: paged\n---\n\n# Data Loading and Cleaning\n\n::: {#0b76940b .cell execution_count=1}\n``` {.python .cell-code}\nfrom pyspark.sql import SparkSession\n\n# Start a Spark session\nspark = SparkSession.builder.appName(\"JobPostingsAnalysis\").getOrCreate()\n\n# Load the CSV file into a Spark DataFrame\ndf = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"../data/lightcast_job_postings.csv\")\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWARNING: Using incubator modules: jdk.incubator.vector\nUsing Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/10/16 06:51:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n\r[Stage 1:>                                                          (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n:::\n\n\n::: {#b2af1de8 .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\nfrom pyspark.sql.functions import when, col\n\n#Clean Data to convert to Pandas\ncolumns_to_drop = [\"ID\", \"BODY\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_4\", \"SOC_5\", \"LAST_UPDATED_DATE\", \"LAST_UPDATED_TIMESTAMP\", \"EXPIRED\", \"SOURCE_TYPES\", \"SOURCES\", \"ACTIVE_SOURCES_INFO\", \"MODELED_EXPIRED\", \"MODELED_DURATION\", \"NAICS2_NAME\", \"NAICS3_NAME\", \"NAICS4_NAME\", \"NAICS5_NAME\", \"NAICS6_NAME\",\n    \"SOC_2_NAME\", \"SOC_3_NAME\", \"SOC_4_NAME\", \"SOC_5_NAME\", \"EDUCATION_LEVELS\", \"MIN_EDULEVELS\"\n    \n]\ncleaned_data = df.drop(*columns_to_drop)\n\ncleaned_data = cleaned_data.withColumn(\n    \"REMOTE_TYPE_NAME\",\n    when(col(\"REMOTE_TYPE_NAME\") == \"Remote\", \"Remote\")\n    .when(col(\"REMOTE_TYPE_NAME\") == \"Hybrid Remote\", \"Hybrid\")\n    .when(col(\"REMOTE_TYPE_NAME\") == \"[None]\", \"On-site\")\n    .when(col(\"REMOTE_TYPE_NAME\").isNull(), \"On-site\")\n    .when(col(\"REMOTE_TYPE_NAME\") == \"Not Remote\", \"On-site\")\n    .otherwise(col(\"REMOTE_TYPE_NAME\"))\n)\n\ncleaned_data = cleaned_data.withColumn(\n    \"EMPLOYMENT_TYPE_NAME\",\n    when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time / full-time\", \"Flexible\")\n    .when(col(\"EMPLOYMENT_TYPE_NAME\").isNull(), \"Full-Time\")\n    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time (â‰¤ 32 hours)\", \"Part-Time\")\n    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Full-time (> 32 hours)\", \"Full-Time\")\n    .otherwise(col(\"EMPLOYMENT_TYPE_NAME\")) \n)\n\ncleaned_data = cleaned_data.filter(col(\"NAICS_2022_2_NAME\") != \"Unclassified Industry\")\n\nmedian_salary = cleaned_data.approxQuantile(\"SALARY\", [0.5], 0.01)[0]\ncleaned_data = cleaned_data.withColumn(\n    \"SALARY\",\n    when(col(\"SALARY\").isNull(), median_salary).otherwise(col(\"SALARY\"))\n)\n\n#Convert to Pandas\nclean_pdf = cleaned_data.toPandas()\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 2:>                                                          (0 + 1) / 1]\r\r                                                                                \r25/10/16 06:51:50 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n\r[Stage 3:>                                                          (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n:::\n\n\n::: {#45511684 .cell execution_count=3}\n``` {.python .cell-code}\n# Cleaning empty rows and dropping columns that are mostly empty\n\n\nfill_cols = [\"CITY_NAME\", \"CITY\", \"LOCATION\", \"STATE\", \"STATE_NAME\", \"COMPANY\", \"COMPANY_NAME\"]\nclean_pdf[fill_cols] = clean_pdf[fill_cols].fillna(\"Unknown\")\n\nclean_pdf = clean_pdf.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\")\n\nclean_pdf.dropna(thresh=len(clean_pdf)*0.5, axis=1, inplace=True)\n\n#New Column to Classify AI Jobs and Add Month of Posting Date\n\nai_keywords = [\n    \"AI\", \"Machine Learning\", \"Data Scientist\", \"Data Analyst\", \"ML\", \n    \"Artificial Intelligence\", \"Deep Learning\", \"NLP\", \"Predictive Analytics\"\n]\n\n#Function to classify AI vs Non-AI Jobs\ndef classify_ai(title):\n    title_lower = str(title).lower()\n    for keyword in ai_keywords:\n        if keyword.lower() in title_lower:\n            return \"AI\"\n    return \"Non-AI\"\n\nclean_pdf[\"AI_JOB\"] = clean_pdf[\"TITLE_RAW\"].apply(classify_ai)\n\nclean_pdf[\"POSTED\"] = pd.to_datetime(clean_pdf[\"POSTED\"], errors=\"coerce\")\nclean_pdf[\"POSTED_MONTH\"] = clean_pdf[\"POSTED\"].dt.month\n\n#Add column for URBAN vs RURAL\n\nclean_pdf[\"URBAN_RURAL\"] = clean_pdf[\"MSA_NAME\"].apply(lambda x: \"Urban\" if pd.notnull(x) else \"Rural\")\n```\n:::\n\n\n# Model 1: KMeans Clustering \n\nWe applied KMeans clustering to identify patterns in the data. We wanted to each cluster to represent a group of jobs based on characteristics of Salary, AI jobs, remote work, and Urban or Rural locations. We used an elbow method to find the ideal number of clusters, which was 4, though the model didn't reflect as concise groupings as wanted.\n\n**Features:**  \n\nSALARY: Continuous numerical feature to reflect compensation.  \nAI_JOB: Binary feature (AI vs Non-AI), one-hot encoded.  \nREMOTE_TYPE_NAME: One-hot encoded categories (On-site, Remote, Hybrid).  \nURBAN_RURAL: One-hot encoded (Urban or Rural).\n\n**Implications for Job Seekers**  \n\nA job seeker can use this model to see what type of characteristics of a job might be tied to others. For example, AI jobs might yield high salaries, and if we used a reference of industry might be able to find an industry of interest that falls in a cluster that is being regarded in the job hunt. This can also be tied into the Skills Gap Analysis to see what a job seeker should work on in order to be considered for a certain cluster.\n\n::: {#0d8ad0c7 .cell execution_count=4}\n``` {.python .cell-code}\n#KMeans clustering using NAICS as a reference but not a target\n\nfrom sklearn.preprocessing import StandardScaler\n\n# Select features\nfeatures = clean_pdf[[\"SALARY\", \"AI_JOB\", \"REMOTE_TYPE_NAME\", \"URBAN_RURAL\"]]\n\n# One-hot encode categorical columns\nfeatures_encoded = pd.get_dummies(features, columns=[\"AI_JOB\", \"REMOTE_TYPE_NAME\", \"URBAN_RURAL\"], drop_first=True)\n\n# Standardize numerical features (important for KMeans)\nscaler = StandardScaler()\nfeatures_scaled = scaler.fit_transform(features_encoded)\n\nfrom sklearn.cluster import KMeans\n\nk = 4\nkmeans = KMeans(n_clusters=k, random_state=42)\nclean_pdf[\"CLUSTER\"] = kmeans.fit_predict(features_scaled)\n\n#Use Industry Name (NAICS2022) as a reference label\n\ncluster_summary = (\n    clean_pdf.groupby([\"CLUSTER\", \"NAICS_2022_2_NAME\"])\n    .size()\n    .reset_index(name=\"count\")\n    .sort_values([\"CLUSTER\", \"count\"], ascending=[True, False])\n)\n\nprint(cluster_summary)\n\n#Used an Elbow Method to choose the correct number of clusters\n\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\n# Example features\nX = features_encoded.values  # your numerical features\n\nwcss = []\nfor k in range(1, 15):\n    km = KMeans(n_clusters=k, random_state=42)\n    km.fit(X)\n    wcss.append(km.inertia_)\n\nplt.plot(range(1, 15), wcss, marker='o')\nplt.xlabel('Number of Clusters (k)')\nplt.ylabel('WCSS (Inertia)')\nplt.title('Elbow Method')\nplt.show()\n\ncluster_summary.head(20)  # Show top 20 to see patterns\n\none_hot_cols = ['AI_JOB_Non-AI', 'REMOTE_TYPE_NAME_On-site', 'REMOTE_TYPE_NAME_Remote', 'URBAN_RURAL_Urban']\n\nclean_pdf = pd.concat([clean_pdf, features_encoded[one_hot_cols]], axis=1)\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10,6))\nsns.scatterplot(\n    data=clean_pdf,\n    x='SALARY',\n    y='AI_JOB_Non-AI',  \n    hue='CLUSTER',\n    palette='viridis',\n    alpha=0.7\n)\nplt.title(\"KMeans Clustering: Salary vs AI Jobs\")\nplt.xlabel(\"Salary\")\nplt.ylabel(\"AI JOB (1=Non-AI, 0=AI)\")\nplt.legend(title=\"Cluster\")\nplt.tight_layout()\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    CLUSTER                                  NAICS_2022_2_NAME  count\n13        0   Professional, Scientific, and Technical Services   2968\n6         0                              Finance and Insurance   1720\n1         0  Administrative and Support and Waste Managemen...   1598\n10        0                                      Manufacturing    734\n8         0                                        Information    696\n..      ...                                                ...    ...\n60        3                    Accommodation and Food Services    353\n69        3            Management of Companies and Enterprises    146\n71        3      Mining, Quarrying, and Oil and Gas Extraction     95\n63        3                Arts, Entertainment, and Recreation     71\n62        3         Agriculture, Forestry, Fishing and Hunting     45\n\n[80 rows x 3 columns]\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](ml_methods_files/figure-html/cell-5-output-2.png){width=576 height=449}\n:::\n\n::: {.cell-output .cell-output-display}\n![](ml_methods_files/figure-html/cell-5-output-3.png){width=950 height=566}\n:::\n:::\n\n\n::: {#1f035c75 .cell execution_count=5}\n``` {.python .cell-code}\n#Visualizing the NAICS Industries in reference to each cluster\n\n\n\nimport matplotlib.pyplot as plt\n\n\ntop_industries = (\n    clean_pdf.groupby([\"CLUSTER\", \"NAICS_2022_6_NAME\"])\n    .size()\n    .reset_index(name=\"count\")\n)\n\ntop3 = top_industries.groupby(\"CLUSTER\").apply(lambda x: x.nlargest(3, \"count\")).reset_index(drop=True)\n\n\npivot_df = top3.pivot(index=\"CLUSTER\", columns=\"NAICS_2022_6_NAME\", values=\"count\").fillna(0)\n\nprint(pivot_df)\n\npivot_df.plot(kind='bar', stacked=True, figsize=(10,6), colormap=\"viridis\")  \n\nplt.title(\"Top 3 Industries per Cluster\")\nplt.xlabel(\"Cluster\")\nplt.ylabel(\"Number of Job Postings\")\nplt.legend(title=\"Industry\", bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_6131/2483236018.py:14: FutureWarning:\n\nDataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nNAICS_2022_6_NAME  Administrative Management and General Management Consulting Services  \\\nCLUSTER                                                                                   \n0                                                                0.0                      \n1                                                             1414.0                      \n2                                                                0.0                      \n3                                                             2139.0                      \n\nNAICS_2022_6_NAME  Computer Systems Design Services  \\\nCLUSTER                                               \n0                                               0.0   \n1                                             376.0   \n2                                             663.0   \n3                                            2694.0   \n\nNAICS_2022_6_NAME  Custom Computer Programming Services  \\\nCLUSTER                                                   \n0                                                 836.0   \n1                                                   0.0   \n2                                                 720.0   \n3                                                3209.0   \n\nNAICS_2022_6_NAME  Direct Health and Medical Insurance Carriers  \\\nCLUSTER                                                           \n0                                                         685.0   \n1                                                           0.0   \n2                                                           0.0   \n3                                                           0.0   \n\nNAICS_2022_6_NAME  Employment Placement Agencies  \\\nCLUSTER                                            \n0                                          774.0   \n1                                            0.0   \n2                                         1268.0   \n3                                            0.0   \n\nNAICS_2022_6_NAME  Offices of Certified Public Accountants  \nCLUSTER                                                     \n0                                                      0.0  \n1                                                    257.0  \n2                                                      0.0  \n3                                                      0.0  \n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](ml_methods_files/figure-html/cell-6-output-3.png){width=922 height=566}\n:::\n:::\n\n\n## Key Insights\n\nOut of the 4 clusters, it seems like there are 3 fairly clear clusters and 1 that is more ambiguous.\n\nCluster 0: The ambiguous one, doesn't seem to have any groupings along AI, Non-AI, and Salary.  \nCluster 1: This is a group of higher salary paid positions, but are grouped regardless of AI vs Non-AI.  \nCluster 2: These seem to be low paying, AI jobs.  \nCluster 3: These seem to be low paying Non-AI jobs.  \n\n**Industry Relationship:**  \n\nIt seems that the industries don't have as much of a bearing on each cluster. For example, we thought that the high paying clusters would be more tech industry focused, but the low paying cluster also has a large amount of job openings in the same industries. This may mean that salaries are most likely influenced less by Industry and AI impact and influenced more by Skills, seniority, and education.\n\n\n# Model 2: Linear Regression for Salary Prediction\n\nWe ran a linear regression model to predict job salaries based on location, remote status, and urban/rural classification. It estimates/predicts how location and job type impact salary. It’s useful for identifying which factors contribute to higher salaries and preferred work type.\n\n**Features used:**  \n\nSTATE_NAME: One-hot encoded categorical variable representing each state.  \nREMOTE_TYPE_NAME: One-hot encoded (Remote, Hybrid, On-site).  \nURBAN_RURAL: One-hot encoded (Urban vs. Rural).  \nTarget variable: SALARY (numerical).  \n\n**Implications for job seekers:**  \n\nThe model reveals which locations and job types may pay more, which is probably the most important consideration for job seekers.\n\nFor example, remote AI jobs in urban hubs may offer higher salaries than non-AI roles in rural areas.\n\nLimitations: This model focuses only on geographic and job-type features, so salary effects of skills, experience, or certifications are not captured. As we show, geographical data is not a greate predictor or estimator in Salary. We assume that education levels, experience, and skills may be a better predictor.\n\n::: {#9009bb10 .cell execution_count=6}\n``` {.python .cell-code}\n#Predicting Salaries based on Location Data through Linear Regression\n#*Decided to run it in Pandas with Scikit as it's already been converted and cleaned\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nreg_data = clean_pdf[[\"SALARY\", \"STATE_NAME\", \"REMOTE_TYPE_NAME\", \"URBAN_RURAL\"]]\n\nX = pd.get_dummies(reg_data[[\"STATE_NAME\", \"REMOTE_TYPE_NAME\", \"URBAN_RURAL\"]], drop_first=True)\ny = reg_data[\"SALARY\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Evaulation Metrics:\")\nprint(f\"RMSE: {rmse:,.2f}\")\nprint(f\"R2: {r2:.3f}\")\n\ndf_coef = pd.DataFrame({\n    \"Feature\": X.columns,\n    \"Coefficient\": model.coef_\n}).sort_values(by=\"Coefficient\", ascending=False)\n\nprint(\"\\nTop PositiveInfluences on Salary:\")\nprint(df_coef.head(10))\n\nprint(\"\\nTop Negative Influences on Salary:\")\nprint(df_coef.tail(10))\n\n\nplt.figure(figsize=(12,9))\nplt.scatter(y_test, y_pred, alpha=0.5)\nplt.xlabel(\"Actual Salary\")\nplt.ylabel(\"Predicted Salary\")\nplt.title(\"Predicted vs Actual Salaries\")\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\nplt.tight_layout()\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEvaulation Metrics:\nRMSE: 29,689.15\nR2: 0.006\n\nTop PositiveInfluences on Salary:\n                                              Feature  Coefficient\n45                              STATE_NAME_Washington  6361.179175\n5                              STATE_NAME_Connecticut  5837.080401\n43                                 STATE_NAME_Vermont  5302.264696\n3                               STATE_NAME_California  4726.943831\n51                            REMOTE_TYPE_NAME_Remote  4274.612550\n50                           REMOTE_TYPE_NAME_On-site  4176.813834\n2                                 STATE_NAME_Arkansas  4109.440464\n46  STATE_NAME_Washington, D.C. (District of Colum...  2818.294899\n28                              STATE_NAME_New Jersey  2786.906817\n11                                STATE_NAME_Illinois  2575.153394\n\nTop Negative Influences on Salary:\n                     Feature   Coefficient\n49        STATE_NAME_Wyoming  -3610.797563\n47  STATE_NAME_West Virginia  -3985.698913\n22    STATE_NAME_Mississippi  -4039.741194\n15       STATE_NAME_Kentucky  -5710.215799\n0          STATE_NAME_Alaska  -5941.167716\n42           STATE_NAME_Utah  -6390.023354\n26         STATE_NAME_Nevada  -7679.185737\n39   STATE_NAME_South Dakota  -9360.455547\n32   STATE_NAME_North Dakota -10354.011369\n29     STATE_NAME_New Mexico -10744.064282\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](ml_methods_files/figure-html/cell-7-output-2.png){width=1142 height=854}\n:::\n:::\n\n\n## Key Insights\n\n**Evaulation Metrics:**  \nRMSE: 29,689.15   \nR2: 0.006  \n\nThese metrics are saying that our features are not very influential on the salary, meaning that there are most likely better predictors of Salary than geographical predictors. Like previously stated, things like seniority, education, and skills may be better predictors to higher or lower salaries.\n\nAnother insight that might be able to be used by a job seeker might be the highest and negative influencers on salary. Even though our model isn't great, it seems that we can deduce that seeking a job in Washington might yield a higher salary vs. the baseline salary, but seeking a job in New Mexico might yield a lower salary than the baseline.\n\n",
    "supporting": [
      "ml_methods_files"
    ],
    "filters": [],
    "includes": {}
  }
}