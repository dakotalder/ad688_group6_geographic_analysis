{
  "hash": "502a1e7e379054b4d8d29353859233b0",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Geographic Analysis - Group 6\"\nsubtitle: \"Final Report\"\nauthor:\n- name: Dakota Alder\n- name: Julio Garcia\n- affiliations:\n  - id: BU\n    name: Boston University MET\n    city: Boston\n    state: MA\ndate: today\ndate-modified: today\ndate-format: long\nformat: \n    docx: default\n---\n\n\n---\n\ntitle: \"Project Overview\"\nformat: \n  html:\n    theme: cosmo        \n    toc: true           \n    toc-location: left  \n    code-fold: true    \n    number-sections: true\n    css: styles.css     \n\n---\n# Introduction and Research Rationale\n\nArtificial intelligence, also known as AI, is redefining the labor market, shaping not only how work is done but also where work is done. As businesses adopt AI-driven tools and automation, demand for data science, machine learning, and software roles continues to grow, while routine administrative and operational jobs decline (Kahn et al, 2024). This recent shift has created a new geography of employment, where technological infrastructure and remote work options play central roles.\n\nRemote work, accelerated by the COVID-19 pandemic and continued by companies adoption of this practice, has ereated more high-wage, skill-based positions. However, the benefits of this expansion are unevenly distributed as we will see in our analysis. Traditional technology hubs such as Silicon Valley, Austin, and Boston continue to hire a high number of tech/AI affected roles, while smaller metro areas and rural communities face challenges in attracting and retaining AI-related talent (Sheffi, 2024). At the same time, our data shows that remote and hybrid work models are allowing some decentralization, offering emerging regions new opportunities for growth.\n\nThis research analyzes how AI roles and other non-AI roles may be affected by geographic and remote work trends in 2025. The study investigates which states and urban areas demonstrate the highest job growth in AI versus non-AI careers, whether remote positions are increasing across industries, and how urban and rural job markets differ in AI accessibility. Based on our research, it is expected that AI roles will remain concentrated in tech-oriented regions, but it also seems that other non traditional metro areas may be seeing growth not previously seen. Also, remote work is anticipated to remain more prevalent in AI and technology fields, as well as higher salaries in both AI related jobs and remote jobs (Solo et al., 2025). Below are the main focal points of our research:\n\n\n## AI vs. Non-AI Job Growth\n\nPreliminary findings indicate that AI-related positions are growing in states such as Hawaii, Wyoming, and Montana. In contrast, non-AI jobs remain more evenly distributed, with steady growth across states with large service or manufacturing economies.\n\n![AI vs. Non-AI Job Growth - State](../ad688_group6_geographic_analysis/images/top10state.png){fig-align=\"center\" width=\"80%\"}\n\n![AI vs. Non-AI Job Growth - City](../ad688_group6_geographic_analysis/images/top10city.png){fig-align=\"center\" width=\"80%\"}\n\n## Trends in Remote Work Across Industries\n\nRemote job listings continue to represent a significant share of AI-related careers, especially in Finance and Insurance and Information Industries. Conversely, manufacturing and professional and technical services remain predominantly on-site. \n\n![Remote Work Trends](../ad688_group6_geographic_analysis/images/remoteindustries.png){fig-align=\"center\" width=\"80%\"}\n\n## Tech Hubs vs. Emerging Locations\n\nOur data shows that job postings are the highest in the New York, Washington DC, Dallas, and Chicago metro areas, while the traditional tech hubs like Boston, the Bay Area, and Austin actually aren't at the top of job postings anymore. The data suggests that this is mostly due to high populations, so a deeper dive into industry would help in showing emerging markets outside of traditional tech hubs.\n\n![Top 15 Tech Hubs](../ad688_group6_geographic_analysis/images/top15techhubs.png){fig-align=\"center\" width=\"80%\"}\n\n## Urban vs. Rural Dynamics\n\nUrban regions continue to host the majority of AI employment due to their access to universities, data infrastructure, and venture capital. However, remote work options are beginning to bridge the urban-rural divide, allowing rural professionals to participate in digital industries without relocating. Rural job markets, while smaller, show almost exact proportions of AI and Non-AI postings, reflecting that AI jobs as a whole don't necessarily require specific locations.\n\n![Urban and Rural AI Makeup](../ad688_group6_geographic_analysis/images/urbanai.png){fig-align=\"center\" width=\"80%\"}\n\n### References\n\nKhan, A., Shad, F., Sethi, S., & Bibi, M. (2024). The impact of artificial intelligence (AI) on job displacement and the future of work. Social Science Review Archives, 2(2), 2296–2306. https://doi.org/10.70670/SRA.v3i1.509\n\nSheffi, Y. (2024). Technology is not enough: Potential job displacement in an AI-driven future. Journal of Supply Chain Management, Logistics and Procurement, 6(4), 338–351.\n\nSolo, L. B., Hossain, S., & Weah, S. S. II. (2025). AI-powered job market insights: How AI adoption influences salary and job growth projections. North American Academic Research, 8(2), 224–241. https://doi.org/10.5281/zenodo.15212191\n\n---\n\ntitle: \"Data Analysis\"\nsubtitle: \"Comprehensive Data Cleaning & Exploratory Analysis of Geographic Data\"\nauthor:\n  - name: Dakota Alder\n    affiliations:\n      - id: bu\n        name: Boston University\n        city: Boston\n        state: MA\n  - name: Julio Garcia\n    affiliations:\n      - id: bu\n        name: Boston University\n        city: Boston\n        state: MA\n#bibliography: references.bib\n#csl: csl/econometrica.csl\nformat: \n  html:\n    toc: true\n    number-sections: true\n    df-print: paged\n---\n\n# Load and Preview LightCast Data\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom pyspark.sql import SparkSession\n\n\n# Start a Spark session\nspark = SparkSession.builder.appName(\"JobPostingsAnalysis\").getOrCreate()\n\n# Load the CSV file into a Spark DataFrame\ndf = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"../data/lightcast_job_postings.csv\")\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWARNING: Using incubator modules: jdk.incubator.vector\nUsing Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/10/16 03:38:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n\r[Stage 1:>                                                          (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n:::\n\n\n# Drop unnecessary columns\n\nRedundant or irrelevant columns are dropped here.\n\nNAICS and SOC levels are removed because each job is already described by its most detailed (and most general) industry and occupation classification (NAICS_2022_6_NAME and SOC_6_NAME).\n\nTimestamps and system variables (like LAST_UPDATED_TIMESTAMP) are not meaningful.\n\nSimplifying the dataset this way speeds up our processing and makes the whole dataframe look more clean and user-friendly.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\nfrom pyspark.sql.functions import when, col\n\n#Clean Data to convert to Pandas\ncolumns_to_drop = [\"ID\", \"BODY\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_4\", \"SOC_5\", \"LAST_UPDATED_DATE\", \"LAST_UPDATED_TIMESTAMP\", \"EXPIRED\", \"SOURCE_TYPES\", \"SOURCES\", \"ACTIVE_SOURCES_INFO\", \"MODELED_EXPIRED\", \"MODELED_DURATION\", \"NAICS2_NAME\", \"NAICS3_NAME\", \"NAICS4_NAME\", \"NAICS5_NAME\", \"NAICS6_NAME\",\n    \"SOC_2_NAME\", \"SOC_3_NAME\", \"SOC_4_NAME\", \"SOC_5_NAME\", \"EDUCATION_LEVELS\", \"MIN_EDULEVELS\"\n    \n]\ncleaned_data = df.drop(*columns_to_drop)\n\ncleaned_data = cleaned_data.withColumn(\n    \"REMOTE_TYPE_NAME\",\n    when(col(\"REMOTE_TYPE_NAME\") == \"Remote\", \"Remote\")\n    .when(col(\"REMOTE_TYPE_NAME\") == \"Hybrid Remote\", \"Hybrid\")\n    .when(col(\"REMOTE_TYPE_NAME\") == \"[None]\", \"On-site\")\n    .when(col(\"REMOTE_TYPE_NAME\").isNull(), \"On-site\")\n    .when(col(\"REMOTE_TYPE_NAME\") == \"Not Remote\", \"On-site\")\n    .otherwise(col(\"REMOTE_TYPE_NAME\"))\n)\n\ncleaned_data = cleaned_data.withColumn(\n    \"EMPLOYMENT_TYPE_NAME\",\n    when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time / full-time\", \"Flexible\")\n    .when(col(\"EMPLOYMENT_TYPE_NAME\").isNull(), \"Full-Time\")\n    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time (â‰¤ 32 hours)\", \"Part-Time\")\n    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Full-time (> 32 hours)\", \"Full-Time\")\n    .otherwise(col(\"EMPLOYMENT_TYPE_NAME\")) \n)\n\ncleaned_data = cleaned_data.filter(col(\"NAICS_2022_2_NAME\") != \"Unclassified Industry\")\n\nmedian_salary = cleaned_data.approxQuantile(\"SALARY\", [0.5], 0.01)[0]\ncleaned_data = cleaned_data.withColumn(\n    \"SALARY\",\n    when(col(\"SALARY\").isNull(), median_salary).otherwise(col(\"SALARY\"))\n)\n\n\nclean_pdf = cleaned_data.toPandas()\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 2:>                                                          (0 + 1) / 1]\r\r                                                                                \r25/10/16 03:38:55 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n\r[Stage 3:>                                                          (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n:::\n\n\n# Handle Missing Values\n\nWe also cleaned categorical values\n\nMissing categorical data (like City, Company, State) were replaced with \"Unknown\" so that there is data in all rows.\nDuplicates were also dropped to not skew the analysis.\nSalary missing values were replaced with the median salary.\nRemote Type Name and Employment type were simplified into smaller groupings.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nimport missingno as msno\nimport matplotlib.pyplot as plt\n\n# Visualize missing data\nmsno.heatmap(clean_pdf)\nplt.title(\"Missing Values Heatmap\")\nplt.show()\n\nfill_cols = [\"CITY_NAME\", \"CITY\", \"LOCATION\", \"STATE\", \"STATE_NAME\", \"COMPANY\", \"COMPANY_NAME\"]\nclean_pdf[fill_cols] = clean_pdf[fill_cols].fillna(\"Unknown\")\n\nclean_pdf = clean_pdf.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\")\n\nclean_pdf.dropna(thresh=len(clean_pdf)*0.5, axis=1, inplace=True)\n\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-4-output-1.png){}\n:::\n:::\n\n\n# Helper Columns for classifying AI and Posted Dates\n\nWe created columns to classify what job titles may be affected by AI vs Non-AI Job Titles\nWe created a column for the month that the job was posted in order to create growth data\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n#New Column to Classify AI Jobs and Add Month of Posting Date\n\n\nai_keywords = [\n    \"AI\", \"Machine Learning\", \"Data Scientist\", \"Data Analyst\", \"ML\", \n    \"Artificial Intelligence\", \"Deep Learning\", \"NLP\", \"Predictive Analytics\"\n]\n\n#Function to classify AI vs Non-AI Jobs\ndef classify_ai(title):\n    title_lower = str(title).lower()\n    for keyword in ai_keywords:\n        if keyword.lower() in title_lower:\n            return \"AI\"\n    return \"Non-AI\"\n\nclean_pdf[\"AI_JOB\"] = clean_pdf[\"TITLE_RAW\"].apply(classify_ai)\n\nclean_pdf[\"POSTED\"] = pd.to_datetime(clean_pdf[\"POSTED\"], errors=\"coerce\")\nclean_pdf[\"POSTED_MONTH\"] = clean_pdf[\"POSTED\"].dt.month\n\n#clean_pdf.head(25)\n```\n:::\n\n\n# City and State Analysis by AI vs Non-AI Jobs\n\nKey Insights: \n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n#Question 1 Visualization: Which Cities or States have the highest job growth for AI vs Non-AI\n\ncount_by_month_state = (\n  clean_pdf.groupby([\"STATE_NAME\", \"POSTED_MONTH\", \"AI_JOB\"])\n  .size()\n  .reset_index(name=\"count\")\n)\n\ncount_by_month_city = (\n  clean_pdf.groupby([\"CITY_NAME\", \"POSTED_MONTH\", \"AI_JOB\"])\n  .size()\n  .reset_index(name=\"count\")\n)\n\n#Measure job growth by State and then by city\ncount_by_month_state = count_by_month_state.sort_values([\"STATE_NAME\", \"AI_JOB\", \"POSTED_MONTH\"])\ncount_by_month_state[\"GROWTH\"] = (\n  count_by_month_state\n  .groupby([\"STATE_NAME\", \"AI_JOB\"])[\"count\"]\n  .pct_change() * 100\n)\n\ncount_by_month_city = count_by_month_city.sort_values([\"CITY_NAME\", \"AI_JOB\", \"POSTED_MONTH\"])\ncount_by_month_city[\"GROWTH\"] = (\n  count_by_month_city\n  .groupby([\"CITY_NAME\", \"AI_JOB\"])[\"count\"]\n  .pct_change() * 100\n)\n\navg_growth_state = (\n    count_by_month_state.groupby([\"STATE_NAME\", \"AI_JOB\"])[\"GROWTH\"]\n    .mean()\n    .reset_index()\n    .dropna()\n    .sort_values(\"GROWTH\", ascending=False)\n)\n\navg_growth_city = (\n    count_by_month_city.groupby([\"CITY_NAME\", \"AI_JOB\"])[\"GROWTH\"]\n    .mean()\n    .reset_index()\n    .dropna()\n    .sort_values(\"GROWTH\", ascending=False)\n)\n\nprint(\"Top 10 States by AI Job Growth:\")\nprint(avg_growth_state[avg_growth_state[\"AI_JOB\"] == \"AI\"].head(10))\n\nprint(\"\\nTop 10 States by Non-AI Job Growth:\")\nprint(avg_growth_state[avg_growth_state[\"AI_JOB\"] == \"Non-AI\"].head(10))\n\nprint(\"Top 10 Cities by AI Job Growth:\")\nprint(avg_growth_city[avg_growth_city[\"AI_JOB\"] == \"AI\"].head(10))\n\nprint(\"\\nTop 10 Cities by Non-AI Job Growth:\")\nprint(avg_growth_city[avg_growth_city[\"AI_JOB\"] == \"Non-AI\"].head(10))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nstate_visual = avg_growth_state.groupby(\"AI_JOB\").head(10)\n\nplt.figure(figsize=(10,6))\nax_state = sns.barplot(data=state_visual, y=\"STATE_NAME\", x=\"GROWTH\", hue=\"AI_JOB\")\nplt.title(\"Top 10 States by Average Monthly Job Growth: AI vs Non-AI\")\nplt.xlabel(\"Average Monthly Growth (%)\")\nplt.ylabel(\"State\")\n\nfor container in ax_state.containers:\n  ax_state.bar_label(container, fmt=\"%.1f%%\", label_type=\"edge\", padding=3, fontsize=9)\n\nplt.tight_layout()\nplt.savefig(\"../ad688_group6_geographic_analysis/images/top10state.png\", dpi=300)\nplt.show()\n\ncity_visual = avg_growth_city.groupby(\"AI_JOB\").head(10)\n\nplt.figure(figsize=(10,6))\nax_city = sns.barplot(data=city_visual, y=\"CITY_NAME\", x=\"GROWTH\", hue=\"AI_JOB\")\nplt.title(\"Top 10 Cities by Average Monthly Job Growth: AI vs Non-AI\")\nplt.xlabel(\"Average Monthly Growth (%)\")\nplt.ylabel(\"City\")\n\nfor container in ax_city.containers:\n  ax_city.bar_label(container, fmt=\"%.1f%%\", label_type=\"edge\", padding=3, fontsize=9)\n\nplt.tight_layout()\nplt.savefig(\"../ad688_group6_geographic_analysis/images/top10city.png\", dpi=300)\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTop 10 States by AI Job Growth:\n       STATE_NAME AI_JOB      GROWTH\n20         Hawaii     AI  140.217803\n100       Wyoming     AI   90.990260\n50        Montana     AI   67.291667\n46    Mississippi     AI   58.393822\n80   South Dakota     AI   46.527778\n34      Louisiana     AI   41.077075\n32       Kentucky     AI   40.737045\n2          Alaska     AI   40.043290\n52       Nebraska     AI   38.870132\n86           Utah     AI   36.988636\n\nTop 10 States by Non-AI Job Growth:\n                                  STATE_NAME  AI_JOB     GROWTH\n101                                  Wyoming  Non-AI  50.555556\n21                                    Hawaii  Non-AI  49.105634\n97                             West Virginia  Non-AI  43.492753\n67                              North Dakota  Non-AI  32.006313\n81                              South Dakota  Non-AI  31.818182\n47                               Mississippi  Non-AI  28.331625\n57                             New Hampshire  Non-AI  25.913029\n51                                   Montana  Non-AI  25.904481\n53                                  Nebraska  Non-AI  22.365222\n95   Washington, D.C. (District of Columbia)  Non-AI  12.850958\nTop 10 Cities by AI Job Growth:\n                                CITY_NAME AI_JOB       GROWTH\n1366                          Everett, MA     AI  1000.000000\n4155                           Summit, NJ     AI   900.000000\n4876                   [Unknown City], WA     AI   579.875000\n1964                         Honolulu, HI     AI   436.507937\n4743  Wright-Patterson Air Force Base, OH     AI   400.000000\n3133                      North Wales, PA     AI   400.000000\n82                  Altamonte Springs, FL     AI   400.000000\n1072                         Dearborn, MI     AI   391.666667\n2532                           Mahwah, NJ     AI   306.250000\n474                              Brea, CA     AI   300.000000\n\nTop 10 Cities by Non-AI Job Growth:\n               CITY_NAME  AI_JOB       GROWTH\n4877  [Unknown City], WA  Non-AI  1138.925972\n396            Blair, NE  Non-AI   650.000000\n3974          Sidney, OH  Non-AI   600.000000\n4106   State College, PA  Non-AI   510.000000\n4851  [Unknown City], NY  Non-AI   418.161765\n4003          Smyrna, TN  Non-AI   400.000000\n822          Clayton, MO  Non-AI   400.000000\n2101       Jamesburg, NJ  Non-AI   300.000000\n3720        Rosharon, TX  Non-AI   300.000000\n323           Beloit, WI  Non-AI   300.000000\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-6-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-6-output-3.png){}\n:::\n:::\n\n\n## Key Insights\n\nThe analysis shows that AI jobs postings are increasing at a higher rate than Non-AI jobs, and that is especially true in Hawaii, Wyoming, Montana, and Mississippi. However, there seems to be no AI Job growth in multiple states, and an increase in Non-AI jobs in those same states, suggesting that AI isn't quite yet displacing jobs. In fact, there are only a select few states where AI Jobs are increasing, most of the 50 states have an increase in Non-AI jobs.\n\n# Remote Job Growth by Industry\n\nKey Insights: \n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n#Question 2: Are remote jobs increasing or decreasing across industries?\n\nremote_only = clean_pdf[clean_pdf[\"REMOTE_TYPE_NAME\"] == \"Remote\"]\n\nremote_growth = (\n  remote_only.groupby([\"NAICS_2022_2_NAME\", \"POSTED_MONTH\"])\n  .size()\n  .reset_index(name=\"count\")\n)\n\n\ntop_5_industries = (\n  remote_only[\"NAICS_2022_2_NAME\"]\n  .value_counts()\n  .head(5)\n  .index\n)\n\ntop_remote_growth = remote_growth[remote_growth[\"NAICS_2022_2_NAME\"].isin(top_5_industries)]\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 7))\nsns.lineplot(\n    data=top_remote_growth,\n    x=\"POSTED_MONTH\",\n    y=\"count\",\n    hue=\"NAICS_2022_2_NAME\"\n)\nplt.title(\"Remote Job Trends Across Top 10 Industries\")\nplt.xlabel(\"Month\")\nplt.ylabel(\"Number of Job Postings\")\nplt.legend(title=\"Industry\", bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.savefig(\"../ad688_group6_geographic_analysis/images/remoteindustries.png\", dpi=300)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-7-output-1.png){}\n:::\n:::\n\n\n## Key Insights\n\nWhen looking at the growth of Remote jobs by industry, we can see that there is an increase in remote jobs in the Finance and Insurance Industries, the Information Industries, and the Administrative and Support and Waste Management and Remediation Services Industries. This seems to suggest that more tech heavy industries can support and are seeing growth in remote positions, but industries like Professional, Scientific, and Technical Services are actually seeing a decline in remote work. These industries might have job titles that require in person work and assistance, which would lead to on-site.\n\n# Tech-Hubs vs emerging Markets\n\nKey Insights: \n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n#Question #3: Do Tech hubs (Silicon Valley, Austin, Boston) still dominate hiring, or are other locations emerging?\n\ntech_hubs = [\"Austin-Round Rock-Georgetown, TX\", \"Boston-Cambridge-Newton, MA-NH\",\"Los Angeles-Long Beach-Anaheim, CA\",\"San Diego-Chula Vista-Carlsbad, CA\",\"San Francisco-Oakland-Berkeley, CA\",\"San Jose-Sunnyvale-Santa Clara, CA\",\"Seattle-Tacoma-Bellevue, WA\"]\n\n# Create a column classifying if the city is a tech hub\nclean_pdf[\"TECH_HUB\"] = clean_pdf[\"MSA_NAME\"].apply(\n    lambda x: \"Tech Hub\" if x in tech_hubs else \"Other\"\n)\n\n#Count number of postings by Tech Hub\ntech_hub_counts = (\n  clean_pdf.groupby(\"MSA_NAME\")\n  .size()\n  .reset_index(name=\"count\")\n  .sort_values(\"count\", ascending=False)\n)\n\n# Merge to add TECH_HUB classification to each MSA\ntech_hub_counts = tech_hub_counts.merge(\n    clean_pdf[[\"MSA_NAME\", \"TECH_HUB\"]].drop_duplicates(),\n    on=\"MSA_NAME\",\n    how=\"left\"\n)\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(14, 8), constrained_layout=True)\nsns.barplot(\n    data=tech_hub_counts.head(15),\n    x=\"MSA_NAME\",\n    y=\"count\",\n    hue=\"TECH_HUB\",\n    palette=\"viridis\"\n)\nplt.title(\"Top 15 Metro Areas by Count of Job Postings\")\nplt.xlabel(\"Tech Hub\")\nplt.ylabel(\"Number of Job Postings\")\nplt.xticks(rotation=60, ha=\"right\")\n\n# Add labels on top of bars\nfor i, row in tech_hub_counts.head(15).iterrows():\n    plt.text(row[\"count\"] + 100, i, f\"{row['count']:,}\", va=\"center\", fontsize=10)\n\n#plt.tight_layout()\nplt.savefig(\"../ad688_group6_geographic_analysis/images/top15techhubs.png\", dpi=300)\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_2899/3504410272.py:47: UserWarning:\n\nconstrained_layout not applied because axes sizes collapsed to zero.  Try making figure larger or Axes decorations smaller.\n\n/home/ubuntu/ad688_group6_geographic_analysis/.venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning:\n\nconstrained_layout not applied because axes sizes collapsed to zero.  Try making figure larger or Axes decorations smaller.\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-8-output-2.png){}\n:::\n:::\n\n\n## Key Insights\n\nThis plot is showing the concentration of job postings in each of the top 15 metro areas, which is interesting because the top 5 are actually not part of the tech hubs list that we created. Number 6, 7, 8, 11, and 15 are tech hubs, but this goes to show that a job seeker does not need to be in a tech hub for job searching. There are plenty of high population, metro areas that will have plenty of jobs. We would like to go further and look at industry and AI jobs as well, which is found in the next plot.\n\n# A Comparison of the Urban and Rural Job Market in relation to AI Careers\n\nKey Insights: \n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# Question 4: How do Urban vs. Rural Job markets differ for AI and non-AI careers?\n\n# Classify as 'Urban' if MSA_NAME is present, else 'Rural'\nclean_pdf[\"URBAN_RURAL\"] = clean_pdf[\"MSA_NAME\"].apply(lambda x: \"Urban\" if pd.notnull(x) else \"Rural\")\n\n# Group data by month, urban/rural, and AI vs Non-AI\nurban_rural_jobs = (\n    clean_pdf.groupby([\"URBAN_RURAL\", \"AI_JOB\"])\n    .size()\n    .reset_index(name=\"count\")\n)\n\n#Calculate percentages\nurban_rural_jobs[\"PERCENT\"] = (\n  urban_rural_jobs.groupby(\"URBAN_RURAL\")[\"count\"]\n  .apply(lambda x: 100 * x / x.sum())\n  .values\n)\n\n#Convert Percentage into 2 decimal places\n\nurban_rural_jobs[\"PERCENT\"] = urban_rural_jobs[\"PERCENT\"].apply(lambda x:f\"{x:.2f}%\")\n\n# Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 6))\nax_urban = sns.barplot(\n    data=urban_rural_jobs,\n    x=\"URBAN_RURAL\",\n    y=\"count\",\n    hue=\"AI_JOB\",\n    palette=\"viridis\"\n)\n\nplt.title(\"AI vs Non-AI Jobs in Urban vs Rural Areas\")\nplt.xlabel(\"Urban or Rural\")\nplt.ylabel(\"Number of Job Postings\")\nplt.legend(title=\"Job Type\")\n\nfor container in ax_urban.containers:\n  ax_urban.bar_label(container, fmt=\"%d\", label_type=\"edge\", padding=3, fontsize=11)\nplt.tight_layout()\nplt.savefig(\"../ad688_group6_geographic_analysis/images/urbanai.png\", dpi=300)\nplt.show()\n\nfig, ax = plt.subplots(figsize=(7,4))  \nax.axis('off') \n\ntable = ax.table(\n    cellText=urban_rural_jobs.values,\n    colLabels=urban_rural_jobs.columns,\n    cellLoc='center',\n    loc='center',\n    colColours=[\"#0b2545\"]*len(urban_rural_jobs.columns),  # Dark blue header\n    colWidths=[0.3]*len(urban_rural_jobs.columns)\n)\n\ntable.auto_set_font_size(False)\ntable.set_fontsize(12)\ntable.scale(1.2, 1.2) \n\nfor key, cell in table.get_celld().items():\n  if key[0] == 0:\n    cell.set_fontsize(14)\n    cell.set_text_props(color='white')\n    cell.set_facecolor('#0b2545')\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-9-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-9-output-2.png){}\n:::\n:::\n\n\n## Key Insights\n\nThis plot shows that the percentage of AI Jobs in Urban areas is actually almost exactly equal to the percentage of AI Jobs in rural areas. Even though the count of these types of jobs are much different, there are opportunities for job seekers to find AI related jobs at the same rate in rural areas compared to urban areas.\n\n---\ntitle: \"Skills Gap Analysis\"\n---\n\n# Skills Gap Analysis\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nfrom pyspark.sql import SparkSession\n\n\n# Start a Spark session\nspark = SparkSession.builder.appName(\"JobPostingsAnalysis\").getOrCreate()\n\n# Load the CSV file into a Spark DataFrame\ndf = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"../data/lightcast_job_postings.csv\")\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 5:>                                                          (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nimport pandas as pd\n\ncolumns = [\n    \"COMPANY_NAME\", \"COMPANY_IS_STAFFING\",              # Identification, company\n    \"POSTED\", \"EXPIRED\", \"DURATION\", \"MODELED_DURATION\", # Dates, duration\n    \"TITLE_NAME\", \"EMPLOYMENT_TYPE_NAME\", \"IS_INTERNSHIP\", # Job title, contract type\n    \"CITY_NAME\", \"STATE_NAME\", \"REMOTE_TYPE_NAME\",       # Geographic\n    \"MIN_YEARS_EXPERIENCE\", \"MIN_EDULEVELS_NAME\", \"EDUCATION_LEVELS_NAME\", # Education, experience\n    \"SALARY\",                                             # Salary\n    \"SKILLS_NAME\", \"SPECIALIZED_SKILLS_NAME\", \"SOFTWARE_SKILLS_NAME\", # Tech skills\n    \"COMMON_SKILLS_NAME\",                                # Common, soft skills\n    \"CERTIFICATIONS_NAME\"                                # Certif\n]\n\n\ndf_columns = df.limit(4000).select([c for c in columns if c in df.columns])\ndf_columns_pd=df_columns.toPandas()\n\nskill_cols = [\n\"SKILLS_NAME\",\n\"SPECIALIZED_SKILLS_NAME\",\n\"SOFTWARE_SKILLS_NAME\",\n\"COMMON_SKILLS_NAME\",\n\"CERTIFICATIONS_NAME\"\n]\n\ndf_columns_pd[\"ALL_SKILLS_RAW\"] = df_columns_pd[skill_cols].fillna(\"\").agg(\" \".join, axis=1)\ndf_columns_pd[\"ALL_SKILLS_RAW\"] = (\n    df_columns_pd[skill_cols]\n    .fillna(\"\")\n    .agg(\" \".join, axis=1)\n    .astype(str)\n    .str.replace(r\"[{}\\[\\]'\\\"]\", \"\", regex=True)      # quita corchetes y comillas\n    .str.replace(r\"\\b[Nn]one\\b|nan\", \"\", regex=True)  # quita None/nan\n    .str.replace(r\"[;|/]\", \",\", regex=True)           # normaliza separadores\n    .str.replace(r\"\\s*,\\s*\", \", \", regex=True)        # limpia espacios entre comas\n    .str.replace(r\"\\s{2,}\", \" \", regex=True)          # elimina espacios dobles\n    .str.strip()                                      # quita espacios extra\n)\nprint(df_columns_pd[\"ALL_SKILLS_RAW\"].head(5))\npd.set_option('display.max_colwidth', None); print(df_columns_pd[\"ALL_SKILLS_RAW\"].head(5).to_string(index=False))\n\n\n\n# skills text to list.\ndf_columns_pd[\"ALL_SKILLS_LIST\"] = df_columns_pd[\"ALL_SKILLS_RAW\"].str.split(\",\")\n\n# list to row\ndf_skills = df_columns_pd.explode(\"ALL_SKILLS_LIST\")\n\n# Clean up spaces and drop empty rows\ndf_skills = ( df_skills.dropna(subset=[\"ALL_SKILLS_LIST\"]).loc[df_skills[\"ALL_SKILLS_LIST\"].str.strip() != \"\"])\ndf_skills[\"ALL_SKILLS_LIST\"] = ( df_skills[\"ALL_SKILLS_LIST\"] .str.strip() .str.title())\n\n# Count skills\ntop_skills = (df_skills[\"ALL_SKILLS_LIST\"].value_counts().reset_index().rename(columns={\"index\": \"Skill\", \"ALL_SKILLS_LIST\": \"Frequency\"}))\n\n# Show top 20\nprint(top_skills.head(20))\n\n#                                    Frequency  count\n# 0                              Communication   3394\n# 1                 Sql (Programming Language)   3134\n# 2                              Data Analysis   2960\n# 3                                 Management   2116\n# 4                                 Leadership   2023\n# 5              Python (Programming Language)   1837\n# 6                                  Dashboard   1791\n# 7                            Problem Solving   1788\n# 8                            Microsoft Excel   1771\n# 9                           Sap Applications   1658\n# 10                                Operations   1550\n# 11                        Project Management   1528\n# 12                          Business Process   1484\n\n\n\n# 5 expert, 4 Advanced, 3 Intermediate, 2 Basic Knowledge, 1\ntop10_skills = [\n    \"Communication\",\n    \"Sql (Programming Language)\",\n    \"Data Analysis\",\n    \"Management\",\n    \"Leadership\",\n    \"Python (Programming Language)\",\n    \"Dashboard\",\n    \"Problem Solving\",\n    \"Microsoft Excel\",\n    \"Sap Applications\"\n]\n\nskills_data = {\n    \"Skill\": top10_skills,\n    \"Julio\": [3, 4, 4, 4, 3, 3, 4, 4, 5, 4],\n    \"Dakota\": [4, 4, 4, 3, 5, 3, 5, 4, 5, 3]\n}\n\ndf_team = pd.DataFrame(skills_data)\n#df_team\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8,5))\nsns.heatmap(df_team.set_index(\"Skill\"), annot=True, cmap=\"coolwarm\", linewidths=0.5)\nplt.title(\"Team Skill Levels Heatmap – Julio & Dakota\")\nplt.show()\n\n# SKILL GAP (Ideal vs our skills)\ndf_team[\"Gap_Julio\"] = 5 - df_team[\"Julio\"]\ndf_team[\"Gap_Dakota\"] = 5 - df_team[\"Dakota\"]\n\n# SHOT SKILLS\nprint(df_team[[\"Skill\", \"Julio\", \"Dakota\", \"Gap_Julio\", \"Gap_Dakota\"]])\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Melt AND PLOT GAP\ndf_gaps_melted = df_team.melt(\n    id_vars=\"Skill\",\n    value_vars=[\"Gap_Julio\", \"Gap_Dakota\"],\n    var_name=\"Member\",\n    value_name=\"Gap\"\n)\n\nplt.figure(figsize=(9,5))\nsns.barplot(data=df_gaps_melted, x=\"Skill\", y=\"Gap\", hue=\"Member\", palette=\"coolwarm\")\nplt.title(\"Skill Gaps Comparison – Julio vs Dakota (Ideal = 5)\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.ylabel(\"Gap (Difference from Ideal Level 5)\")\nplt.xlabel(\"Skill\")\nplt.legend(title=\"Team Member\")\nplt.tight_layout()\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 6:>                                                          (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n0    Merchandising, Mathematics, Presentations, Pre...\n1    Procurement, Ficial Statements, Oracle Busines...\n2    Management, Exception Reporting, Report Writin...\n3    Exit Strategies, Reliability, User Story, Mana...\n4                                                     \nName: ALL_SKILLS_RAW, dtype: object\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Merchandising, Mathematics, Presentations, Predictive Modeling, Data Modeling, Advanced Analytics, Data Extraction, Statistical Analysis, Data Mining, Business Analysis, Fice, Algorithms, Statistics, SQL (Programming Language), Report Writing, Ad Hoc Reporting, Power BI, Relationship Building, Economics, Business Administration Merchandising, Predictive Modeling, Data Modeling, Advanced Analytics, Data Extraction, Statistical Analysis, Data Mining, Business Analysis, Fice, Algorithms, Statistics, SQL (Programming Language), Ad Hoc Reporting, Power BI, Economics SQL (Programming Language), Power BI Mathematics, Presentations, Report Writing, Relationship Building, Business Administration\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Procurement, Ficial Statements, Oracle Business Intelligence (BI), OBIA, Oracle E-Business Suite, PL, SQL, Supply Chain, Business Intelligence, Oracle Fusion Middleware, Project Accounting Procurement, Ficial Statements, Oracle Business Intelligence (BI), OBIA, Oracle E-Business Suite, PL, SQL, Supply Chain, Business Intelligence, Oracle Fusion Middleware, Project Accounting Oracle Business Intelligence (BI), OBIA, Oracle E-Business Suite, PL, SQL, Oracle Fusion Middleware\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Management, Exception Reporting, Report Writing, Security Clearance, Interpersonal Communications, Ability To Meet Deadlines, Presentations, Writing, Data Analysis, Organizational Skills, Negotiation, Data Integrity, Microsoft Office Exception Reporting, Data Analysis, Data Integrity Microsoft Office Management, Report Writing, Interpersonal Communications, Ability To Meet Deadlines, Presentations, Writing, Organizational Skills, Negotiation, Microsoft Office Security Clearance\nExit Strategies, Reliability, User Story, Management, Strategic Planning, Hardware Configuration Management, On Prem, Agile Methodology, Solution Design, Advanced Analytics, Reengineering, Safety Assurance, Cross-Functional Collaboration, Requirements Elicitation, Business Analysis, Data Management, Data Architecture, Influencing Skills, Market Trend, Business Valuation, Creativity, Innovation, Goverce, Systems Development Life Cycle, Leadership, Test Planning, Multi-Tet Cloud Environments, Scrum (Software Development), Project Management, Operations, Data Migration, Regulatory Compliance, Product Roadmaps, SAS (Software), Troubleshooting (Problem Solving), Quality Assurance, Software As A Service (SaaS), Data Domain, Product Requirements, Data Goverce, Competitive Intelligence, Operations Architecture, Risk Appetite, Google Cloud Platform (GCP), User Feedback Exit Strategies, User Story, Hardware Configuration Management, On Prem, Agile Methodology, Solution Design, Advanced Analytics, Reengineering, Cross-Functional Collaboration, Requirements Elicitation, Business Analysis, Data Management, Data Architecture, Market Trend, Business Valuation, Systems Development Life Cycle, Test Planning, Multi-Tet Cloud Environments, Scrum (Software Development), Project Management, Data Migration, Regulatory Compliance, Product Roadmaps, SAS (Software), Software As A Service (SaaS), Data Domain, Product Requirements, Data Goverce, Competitive Intelligence, Operations Architecture, Risk Appetite, Google Cloud Platform (GCP), User Feedback SAS (Software), Google Cloud Platform (GCP) Reliability, Management, Strategic Planning, Safety Assurance, Influencing Skills, Creativity, Innovation, Goverce, Leadership, Operations, Troubleshooting (Problem Solving), Quality Assurance\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n                                   Frequency  count\n0                              Communication   3394\n1                 Sql (Programming Language)   3134\n2                              Data Analysis   2960\n3                                 Management   2116\n4                                 Leadership   2023\n5              Python (Programming Language)   1837\n6                                  Dashboard   1791\n7                            Problem Solving   1788\n8                            Microsoft Excel   1771\n9                           Sap Applications   1658\n10                                Operations   1550\n11                        Project Management   1528\n12                          Business Process   1484\n13                                      Fice   1437\n14                     Business Requirements   1415\n15                                  Planning   1211\n16                             Presentations   1141\n17                                   Writing   1120\n18                           Detail Oriented   1118\n19  Tableau (Business Intelligence Software)   1116\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-11-output-3.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                           Skill  Julio  Dakota  Gap_Julio  Gap_Dakota\n0                  Communication      3       4          2           1\n1     Sql (Programming Language)      4       4          1           1\n2                  Data Analysis      4       4          1           1\n3                     Management      4       3          1           2\n4                     Leadership      3       5          2           0\n5  Python (Programming Language)      3       3          2           2\n6                      Dashboard      4       5          1           0\n7                Problem Solving      4       4          1           1\n8                Microsoft Excel      5       5          0           0\n9               Sap Applications      4       3          1           2\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-11-output-5.png){}\n:::\n:::\n\n\n# Key Takeaways\n\nJulio: Focus on Communication, Leadership, Python, and Management to reduce gaps\n\nDakota: Focus on Python and Management. Leadership and Dashboard are strong.\n\n## Recommended Actions\n\nTechnical Skills: SQL, Python, Dashboarding; Codecademy, DataCamp, Khan Academy, Coursera\n\nSAP Applications: SAP Learning Hub, openSAP Courses\n\nSoft Skills: Communication: LinkedIn Learning, Coursework\nLeadership and Management: Coursera Management courses\n\n## Team Collaboartion to Bridge Skill Gaps\n\nCross Training among team members on strong skills, team projects to exercise the weaker skills, and track progress.\n\n\n---\n\ntitle: \"Machine Learning Methods\"\nsubtitle: \"Regression, Classification, Topic Insights\"\nauthor:\n  - name: Dakota Alder\n    affiliations:\n      - id: bu\n        name: Boston University\n        city: Boston\n        state: MA\n  - name: Julio Garcia\n    affiliations:\n      - id: bu\n        name: Boston University\n        city: Boston\n        state: MA\nformat: \n  html:\n    toc: true\n    number-sections: true\n    df-print: paged\n---\n\n# Data Loading and Cleaning\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nfrom pyspark.sql import SparkSession\n\n# Start a Spark session\nspark = SparkSession.builder.appName(\"JobPostingsAnalysis\").getOrCreate()\n\n# Load the CSV file into a Spark DataFrame\ndf = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"../data/lightcast_job_postings.csv\")\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 8:>                                                          (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nimport pandas as pd\nfrom pyspark.sql.functions import when, col\n\n#Clean Data to convert to Pandas\ncolumns_to_drop = [\"ID\", \"BODY\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_4\", \"SOC_5\", \"LAST_UPDATED_DATE\", \"LAST_UPDATED_TIMESTAMP\", \"EXPIRED\", \"SOURCE_TYPES\", \"SOURCES\", \"ACTIVE_SOURCES_INFO\", \"MODELED_EXPIRED\", \"MODELED_DURATION\", \"NAICS2_NAME\", \"NAICS3_NAME\", \"NAICS4_NAME\", \"NAICS5_NAME\", \"NAICS6_NAME\",\n    \"SOC_2_NAME\", \"SOC_3_NAME\", \"SOC_4_NAME\", \"SOC_5_NAME\", \"EDUCATION_LEVELS\", \"MIN_EDULEVELS\"\n    \n]\ncleaned_data = df.drop(*columns_to_drop)\n\ncleaned_data = cleaned_data.withColumn(\n    \"REMOTE_TYPE_NAME\",\n    when(col(\"REMOTE_TYPE_NAME\") == \"Remote\", \"Remote\")\n    .when(col(\"REMOTE_TYPE_NAME\") == \"Hybrid Remote\", \"Hybrid\")\n    .when(col(\"REMOTE_TYPE_NAME\") == \"[None]\", \"On-site\")\n    .when(col(\"REMOTE_TYPE_NAME\").isNull(), \"On-site\")\n    .when(col(\"REMOTE_TYPE_NAME\") == \"Not Remote\", \"On-site\")\n    .otherwise(col(\"REMOTE_TYPE_NAME\"))\n)\n\ncleaned_data = cleaned_data.withColumn(\n    \"EMPLOYMENT_TYPE_NAME\",\n    when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time / full-time\", \"Flexible\")\n    .when(col(\"EMPLOYMENT_TYPE_NAME\").isNull(), \"Full-Time\")\n    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time (â‰¤ 32 hours)\", \"Part-Time\")\n    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Full-time (> 32 hours)\", \"Full-Time\")\n    .otherwise(col(\"EMPLOYMENT_TYPE_NAME\")) \n)\n\ncleaned_data = cleaned_data.filter(col(\"NAICS_2022_2_NAME\") != \"Unclassified Industry\")\n\nmedian_salary = cleaned_data.approxQuantile(\"SALARY\", [0.5], 0.01)[0]\ncleaned_data = cleaned_data.withColumn(\n    \"SALARY\",\n    when(col(\"SALARY\").isNull(), median_salary).otherwise(col(\"SALARY\"))\n)\n\n#Convert to Pandas\nclean_pdf = cleaned_data.toPandas()\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 9:>                                                          (0 + 1) / 1]\r\r                                                                                \r\r[Stage 10:>                                                         (0 + 1) / 1]\r\r                                                                                \r\n```\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n# Cleaning empty rows and dropping columns that are mostly empty\n\n\nfill_cols = [\"CITY_NAME\", \"CITY\", \"LOCATION\", \"STATE\", \"STATE_NAME\", \"COMPANY\", \"COMPANY_NAME\"]\nclean_pdf[fill_cols] = clean_pdf[fill_cols].fillna(\"Unknown\")\n\nclean_pdf = clean_pdf.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\")\n\nclean_pdf.dropna(thresh=len(clean_pdf)*0.5, axis=1, inplace=True)\n\n#New Column to Classify AI Jobs and Add Month of Posting Date\n\nai_keywords = [\n    \"AI\", \"Machine Learning\", \"Data Scientist\", \"Data Analyst\", \"ML\", \n    \"Artificial Intelligence\", \"Deep Learning\", \"NLP\", \"Predictive Analytics\"\n]\n\n#Function to classify AI vs Non-AI Jobs\ndef classify_ai(title):\n    title_lower = str(title).lower()\n    for keyword in ai_keywords:\n        if keyword.lower() in title_lower:\n            return \"AI\"\n    return \"Non-AI\"\n\nclean_pdf[\"AI_JOB\"] = clean_pdf[\"TITLE_RAW\"].apply(classify_ai)\n\nclean_pdf[\"POSTED\"] = pd.to_datetime(clean_pdf[\"POSTED\"], errors=\"coerce\")\nclean_pdf[\"POSTED_MONTH\"] = clean_pdf[\"POSTED\"].dt.month\n\n#Add column for URBAN vs RURAL\n\nclean_pdf[\"URBAN_RURAL\"] = clean_pdf[\"MSA_NAME\"].apply(lambda x: \"Urban\" if pd.notnull(x) else \"Rural\")\n```\n:::\n\n\n# Model 1: KMeans Clustering \n\nWe applied KMeans clustering to identify patterns in the data. We wanted to each cluster to represent a group of jobs based on characteristics of Salary, AI jobs, remote work, and Urban or Rural locations. We used an elbow method to find the ideal number of clusters, which was 4, though the model didn't reflect as concise groupings as wanted.\n\n**Features:**  \n\nSALARY: Continuous numerical feature to reflect compensation.  \nAI_JOB: Binary feature (AI vs Non-AI), one-hot encoded.  \nREMOTE_TYPE_NAME: One-hot encoded categories (On-site, Remote, Hybrid).  \nURBAN_RURAL: One-hot encoded (Urban or Rural).\n\n**Implications for Job Seekers**  \n\nA job seeker can use this model to see what type of characteristics of a job might be tied to others. For example, AI jobs might yield high salaries, and if we used a reference of industry might be able to find an industry of interest that falls in a cluster that is being regarded in the job hunt. This can also be tied into the Skills Gap Analysis to see what a job seeker should work on in order to be considered for a certain cluster.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n#KMeans clustering using NAICS as a reference but not a target\n\nfrom sklearn.preprocessing import StandardScaler\n\n# Select features\nfeatures = clean_pdf[[\"SALARY\", \"AI_JOB\", \"REMOTE_TYPE_NAME\", \"URBAN_RURAL\"]]\n\n# One-hot encode categorical columns\nfeatures_encoded = pd.get_dummies(features, columns=[\"AI_JOB\", \"REMOTE_TYPE_NAME\", \"URBAN_RURAL\"], drop_first=True)\n\n# Standardize numerical features (important for KMeans)\nscaler = StandardScaler()\nfeatures_scaled = scaler.fit_transform(features_encoded)\n\nfrom sklearn.cluster import KMeans\n\nk = 4\nkmeans = KMeans(n_clusters=k, random_state=42)\nclean_pdf[\"CLUSTER\"] = kmeans.fit_predict(features_scaled)\n\n#Use Industry Name (NAICS2022) as a reference label\n\ncluster_summary = (\n    clean_pdf.groupby([\"CLUSTER\", \"NAICS_2022_2_NAME\"])\n    .size()\n    .reset_index(name=\"count\")\n    .sort_values([\"CLUSTER\", \"count\"], ascending=[True, False])\n)\n\nprint(cluster_summary)\n\n#Used an Elbow Method to choose the correct number of clusters\n\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\n# Example features\nX = features_encoded.values  # your numerical features\n\nwcss = []\nfor k in range(1, 15):\n    km = KMeans(n_clusters=k, random_state=42)\n    km.fit(X)\n    wcss.append(km.inertia_)\n\nplt.plot(range(1, 15), wcss, marker='o')\nplt.xlabel('Number of Clusters (k)')\nplt.ylabel('WCSS (Inertia)')\nplt.title('Elbow Method')\nplt.show()\n\ncluster_summary.head(20)  # Show top 20 to see patterns\n\none_hot_cols = ['AI_JOB_Non-AI', 'REMOTE_TYPE_NAME_On-site', 'REMOTE_TYPE_NAME_Remote', 'URBAN_RURAL_Urban']\n\nclean_pdf = pd.concat([clean_pdf, features_encoded[one_hot_cols]], axis=1)\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10,6))\nsns.scatterplot(\n    data=clean_pdf,\n    x='SALARY',\n    y='AI_JOB_Non-AI',  \n    hue='CLUSTER',\n    palette='viridis',\n    alpha=0.7\n)\nplt.title(\"KMeans Clustering: Salary vs AI Jobs\")\nplt.xlabel(\"Salary\")\nplt.ylabel(\"AI JOB (1=Non-AI, 0=AI)\")\nplt.legend(title=\"Cluster\")\nplt.tight_layout()\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    CLUSTER  \\\n13        0   \n6         0   \n1         0   \n10        0   \n8         0   \n..      ...   \n60        3   \n69        3   \n71        3   \n63        3   \n62        3   \n\n                                                           NAICS_2022_2_NAME  \\\n13                          Professional, Scientific, and Technical Services   \n6                                                      Finance and Insurance   \n1   Administrative and Support and Waste Management and Remediation Services   \n10                                                             Manufacturing   \n8                                                                Information   \n..                                                                       ...   \n60                                           Accommodation and Food Services   \n69                                   Management of Companies and Enterprises   \n71                             Mining, Quarrying, and Oil and Gas Extraction   \n63                                       Arts, Entertainment, and Recreation   \n62                                Agriculture, Forestry, Fishing and Hunting   \n\n    count  \n13   2968  \n6    1720  \n1    1598  \n10    734  \n8     696  \n..    ...  \n60    353  \n69    146  \n71     95  \n63     71  \n62     45  \n\n[80 rows x 3 columns]\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-15-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-15-output-3.png){}\n:::\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n#Visualizing the NAICS Industries in reference to each cluster\n\n\n\nimport matplotlib.pyplot as plt\n\n\ntop_industries = (\n    clean_pdf.groupby([\"CLUSTER\", \"NAICS_2022_6_NAME\"])\n    .size()\n    .reset_index(name=\"count\")\n)\n\ntop3 = top_industries.groupby(\"CLUSTER\").apply(lambda x: x.nlargest(3, \"count\")).reset_index(drop=True)\n\n\npivot_df = top3.pivot(index=\"CLUSTER\", columns=\"NAICS_2022_6_NAME\", values=\"count\").fillna(0)\n\nprint(pivot_df)\n\npivot_df.plot(kind='bar', stacked=True, figsize=(10,6), colormap='tab20')  \n\nplt.title(\"Top 3 Industries per Cluster\")\nplt.xlabel(\"Cluster\")\nplt.ylabel(\"Number of Job Postings\")\nplt.legend(title=\"Industry\", bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_2899/24634743.py:14: FutureWarning:\n\nDataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nNAICS_2022_6_NAME  Administrative Management and General Management Consulting Services  \\\nCLUSTER                                                                                   \n0                                                                                   0.0   \n1                                                                                1414.0   \n2                                                                                   0.0   \n3                                                                                2139.0   \n\nNAICS_2022_6_NAME  Computer Systems Design Services  \\\nCLUSTER                                               \n0                                               0.0   \n1                                             376.0   \n2                                             663.0   \n3                                            2694.0   \n\nNAICS_2022_6_NAME  Custom Computer Programming Services  \\\nCLUSTER                                                   \n0                                                 836.0   \n1                                                   0.0   \n2                                                 720.0   \n3                                                3209.0   \n\nNAICS_2022_6_NAME  Direct Health and Medical Insurance Carriers  \\\nCLUSTER                                                           \n0                                                         685.0   \n1                                                           0.0   \n2                                                           0.0   \n3                                                           0.0   \n\nNAICS_2022_6_NAME  Employment Placement Agencies  \\\nCLUSTER                                            \n0                                          774.0   \n1                                            0.0   \n2                                         1268.0   \n3                                            0.0   \n\nNAICS_2022_6_NAME  Offices of Certified Public Accountants  \nCLUSTER                                                     \n0                                                      0.0  \n1                                                    257.0  \n2                                                      0.0  \n3                                                      0.0  \n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-16-output-3.png){}\n:::\n:::\n\n\n## Key Insights\n\nOut of the 4 clusters, it seems like there are 3 fairly clear clusters and 1 that is more ambiguous.\n\nCluster 0: The ambiguous one, doesn't seem to have any groupings along AI, Non-AI, and Salary.  \nCluster 1: This is a group of higher salary paid positions, but are grouped regardless of AI vs Non-AI.  \nCluster 2: These seem to be low paying, AI jobs.  \nCluster 3: These seem to be low paying Non-AI jobs.  \n\n**Industry Relationship:**  \n\nIt seems that the industries don't have as much of a bearing on each cluster. For example, we thought that the high paying clusters would be more tech industry focused, but the low paying cluster also has a large amount of job openings in the same industries. This may mean that salaries are most likely influenced less by Industry and AI impact and influenced more by Skills, seniority, and education.\n\n\n# Model 2: Linear Regression for Salary Prediction\n\nWe ran a linear regression model to predict job salaries based on location, remote status, and urban/rural classification. It estimates/predicts how location and job type impact salary. It’s useful for identifying which factors contribute to higher salaries and preferred work type.\n\n**Features used:**  \n\nSTATE_NAME: One-hot encoded categorical variable representing each state.  \nREMOTE_TYPE_NAME: One-hot encoded (Remote, Hybrid, On-site).  \nURBAN_RURAL: One-hot encoded (Urban vs. Rural).  \nTarget variable: SALARY (numerical).  \n\n**Implications for job seekers:**  \n\nThe model reveals which locations and job types may pay more, which is probably the most important consideration for job seekers.\n\nFor example, remote AI jobs in urban hubs may offer higher salaries than non-AI roles in rural areas.\n\nLimitations: This model focuses only on geographic and job-type features, so salary effects of skills, experience, or certifications are not captured. As we show, geographical data is not a greate predictor or estimator in Salary. We assume that education levels, experience, and skills may be a better predictor.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\n#Predicting Salaries based on Location Data through Linear Regression\n#*Decided to run it in Pandas with Scikit as it's already been converted and cleaned\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nreg_data = clean_pdf[[\"SALARY\", \"STATE_NAME\", \"REMOTE_TYPE_NAME\", \"URBAN_RURAL\"]]\n\nX = pd.get_dummies(reg_data[[\"STATE_NAME\", \"REMOTE_TYPE_NAME\", \"URBAN_RURAL\"]], drop_first=True)\ny = reg_data[\"SALARY\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Evaulation Metrics:\")\nprint(f\"RMSE: {rmse:,.2f}\")\nprint(f\"R2: {r2:.3f}\")\n\ndf_coef = pd.DataFrame({\n    \"Feature\": X.columns,\n    \"Coefficient\": model.coef_\n}).sort_values(by=\"Coefficient\", ascending=False)\n\nprint(\"\\nTop PositiveInfluences on Salary:\")\nprint(df_coef.head(10))\n\nprint(\"\\nTop Negative Influences on Salary:\")\nprint(df_coef.tail(10))\n\n\nplt.figure(figsize=(12,9))\nplt.scatter(y_test, y_pred, alpha=0.5)\nplt.xlabel(\"Actual Salary\")\nplt.ylabel(\"Predicted Salary\")\nplt.title(\"Predicted vs Actual Salaries\")\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\nplt.tight_layout()\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEvaulation Metrics:\nRMSE: 29,689.15\nR2: 0.006\n\nTop PositiveInfluences on Salary:\n                                               Feature  Coefficient\n45                               STATE_NAME_Washington  6361.179175\n5                               STATE_NAME_Connecticut  5837.080401\n43                                  STATE_NAME_Vermont  5302.264696\n3                                STATE_NAME_California  4726.943831\n51                             REMOTE_TYPE_NAME_Remote  4274.612550\n50                            REMOTE_TYPE_NAME_On-site  4176.813834\n2                                  STATE_NAME_Arkansas  4109.440464\n46  STATE_NAME_Washington, D.C. (District of Columbia)  2818.294899\n28                               STATE_NAME_New Jersey  2786.906817\n11                                 STATE_NAME_Illinois  2575.153394\n\nTop Negative Influences on Salary:\n                     Feature   Coefficient\n49        STATE_NAME_Wyoming  -3610.797563\n47  STATE_NAME_West Virginia  -3985.698913\n22    STATE_NAME_Mississippi  -4039.741194\n15       STATE_NAME_Kentucky  -5710.215799\n0          STATE_NAME_Alaska  -5941.167716\n42           STATE_NAME_Utah  -6390.023354\n26         STATE_NAME_Nevada  -7679.185737\n39   STATE_NAME_South Dakota  -9360.455547\n32   STATE_NAME_North Dakota -10354.011369\n29     STATE_NAME_New Mexico -10744.064282\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-17-output-2.png){}\n:::\n:::\n\n\n## Key Insights\n\n**Evaulation Metrics:**  \nRMSE: 29,689.15   \nR2: 0.006  \n\nThese metrics are saying that our features are not very influential on the salary, meaning that there are most likely better predictors of Salary than geographical predictors. Like previously stated, things like seniority, education, and skills may be better predictors to higher or lower salaries.\n\nAnother insight that might be able to be used by a job seeker might be the highest and negative influencers on salary. Even though our model isn't great, it seems that we can deduce that seeking a job in Washington might yield a higher salary vs. the baseline salary, but seeking a job in New Mexico might yield a lower salary than the baseline.\n\n",
    "supporting": [
      "final_report_files"
    ],
    "filters": []
  }
}